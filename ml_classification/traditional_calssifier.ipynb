{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Classifier: BornClassifier\n",
      "Performing grid search for BornClassifier...\n",
      "Best parameters for BornClassifier: {'a': 0.5, 'b': 1, 'h': 0.3}\n",
      "================================================================================\n",
      "Classifier: Nearest Neighbors\n",
      "Performing grid search for Nearest Neighbors...\n",
      "Best parameters for Nearest Neighbors: {'n_neighbors': 2}\n",
      "================================================================================\n",
      "Classifier: Linear SVM\n",
      "Performing grid search for Linear SVM...\n",
      "Best parameters for Linear SVM: {'C': 0.1}\n",
      "================================================================================\n",
      "Classifier: RBF SVM\n",
      "Performing grid search for RBF SVM...\n",
      "Best parameters for RBF SVM: {'C': 10, 'gamma': 'scale'}\n",
      "================================================================================\n",
      "Classifier: Random Forest\n",
      "Performing grid search for Random Forest...\n",
      "Best parameters for Random Forest: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "================================================================================\n",
      "Classifier: Neural Net\n",
      "Performing grid search for Neural Net...\n",
      "Best parameters for Neural Net: {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (100,)}\n",
      "================================================================================\n",
      "Classifier: AdaBoost\n",
      "Performing grid search for AdaBoost...\n",
      "Best parameters for AdaBoost: {'learning_rate': 1.5, 'n_estimators': 100}\n",
      "================================================================================\n",
      "Classifier: Naive Bayes\n",
      "Performing grid search for Naive Bayes...\n",
      "Best parameters for Naive Bayes: {'alpha': 0.5}\n",
      "================================================================================\n",
      "Classifier: QDA\n",
      "Performing grid search for QDA...\n",
      "Best parameters for QDA: {'reg_param': 0.0}\n",
      "================================================================================\n",
      "\n",
      "Results Summary:\n",
      "\n",
      "Classifier: **BornClassifier**\n",
      "----------------------------------------\n",
      "Training Set Results:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Derogatory       0.82      0.93      0.88       227\n",
      "Formal/Polite       0.95      0.86      0.91       687\n",
      "     Informal       0.87      0.87      0.87       498\n",
      "        Taboo       0.66      1.00      0.80        76\n",
      "\n",
      "     accuracy                           0.88      1488\n",
      "    macro avg       0.83      0.92      0.86      1488\n",
      " weighted avg       0.89      0.88      0.88      1488\n",
      "\n",
      "Test Set Results:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Derogatory       0.34      0.52      0.41        52\n",
      "Formal/Polite       0.77      0.73      0.75       182\n",
      "     Informal       0.62      0.49      0.55       123\n",
      "        Taboo       0.25      0.40      0.31        15\n",
      "\n",
      "     accuracy                           0.60       372\n",
      "    macro avg       0.49      0.53      0.50       372\n",
      " weighted avg       0.64      0.60      0.62       372\n",
      "\n",
      "\n",
      "\n",
      "Classifier: Nearest Neighbors\n",
      "----------------------------------------\n",
      "Training Set Results:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Derogatory       0.67      0.99      0.80       227\n",
      "Formal/Polite       0.81      0.93      0.87       687\n",
      "     Informal       0.92      0.63      0.75       498\n",
      "        Taboo       1.00      0.32      0.48        76\n",
      "\n",
      "     accuracy                           0.81      1488\n",
      "    macro avg       0.85      0.72      0.72      1488\n",
      " weighted avg       0.84      0.81      0.80      1488\n",
      "\n",
      "Test Set Results:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Derogatory       0.26      0.40      0.31        52\n",
      "Formal/Polite       0.61      0.76      0.67       182\n",
      "     Informal       0.55      0.28      0.37       123\n",
      "        Taboo       0.00      0.00      0.00        15\n",
      "\n",
      "     accuracy                           0.52       372\n",
      "    macro avg       0.35      0.36      0.34       372\n",
      " weighted avg       0.51      0.52      0.50       372\n",
      "\n",
      "\n",
      "\n",
      "Classifier: Linear SVM\n",
      "----------------------------------------\n",
      "Training Set Results:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Derogatory       0.96      0.92      0.94       227\n",
      "Formal/Polite       0.94      0.97      0.96       687\n",
      "     Informal       0.95      0.94      0.94       498\n",
      "        Taboo       0.94      0.88      0.91        76\n",
      "\n",
      "     accuracy                           0.95      1488\n",
      "    macro avg       0.95      0.93      0.94      1488\n",
      " weighted avg       0.95      0.95      0.95      1488\n",
      "\n",
      "Test Set Results:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Derogatory       0.35      0.33      0.34        52\n",
      "Formal/Polite       0.70      0.78      0.74       182\n",
      "     Informal       0.56      0.53      0.54       123\n",
      "        Taboo       0.33      0.07      0.11        15\n",
      "\n",
      "     accuracy                           0.60       372\n",
      "    macro avg       0.48      0.43      0.43       372\n",
      " weighted avg       0.59      0.60      0.59       372\n",
      "\n",
      "\n",
      "\n",
      "Classifier: RBF SVM\n",
      "----------------------------------------\n",
      "Training Set Results:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Derogatory       0.98      0.91      0.94       227\n",
      "Formal/Polite       0.94      0.98      0.96       687\n",
      "     Informal       0.95      0.94      0.95       498\n",
      "        Taboo       1.00      0.84      0.91        76\n",
      "\n",
      "     accuracy                           0.95      1488\n",
      "    macro avg       0.97      0.92      0.94      1488\n",
      " weighted avg       0.95      0.95      0.95      1488\n",
      "\n",
      "Test Set Results:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Derogatory       0.44      0.33      0.37        52\n",
      "Formal/Polite       0.67      0.74      0.70       182\n",
      "     Informal       0.52      0.56      0.54       123\n",
      "        Taboo       0.00      0.00      0.00        15\n",
      "\n",
      "     accuracy                           0.59       372\n",
      "    macro avg       0.41      0.41      0.40       372\n",
      " weighted avg       0.56      0.59      0.58       372\n",
      "\n",
      "\n",
      "\n",
      "Classifier: Random Forest\n",
      "----------------------------------------\n",
      "Training Set Results:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Derogatory       0.95      0.93      0.94       227\n",
      "Formal/Polite       0.96      0.96      0.96       687\n",
      "     Informal       0.94      0.96      0.95       498\n",
      "        Taboo       0.94      0.89      0.92        76\n",
      "\n",
      "     accuracy                           0.95      1488\n",
      "    macro avg       0.95      0.94      0.94      1488\n",
      " weighted avg       0.95      0.95      0.95      1488\n",
      "\n",
      "Test Set Results:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Derogatory       0.67      0.19      0.30        52\n",
      "Formal/Polite       0.62      0.85      0.72       182\n",
      "     Informal       0.55      0.48      0.51       123\n",
      "        Taboo       0.00      0.00      0.00        15\n",
      "\n",
      "     accuracy                           0.60       372\n",
      "    macro avg       0.46      0.38      0.38       372\n",
      " weighted avg       0.58      0.60      0.56       372\n",
      "\n",
      "\n",
      "\n",
      "Classifier: Neural Net\n",
      "----------------------------------------\n",
      "Training Set Results:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Derogatory       0.94      0.94      0.94       227\n",
      "Formal/Polite       0.94      0.98      0.96       687\n",
      "     Informal       0.98      0.91      0.94       498\n",
      "        Taboo       0.89      0.96      0.92        76\n",
      "\n",
      "     accuracy                           0.95      1488\n",
      "    macro avg       0.94      0.95      0.94      1488\n",
      " weighted avg       0.95      0.95      0.95      1488\n",
      "\n",
      "Test Set Results:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Derogatory       0.41      0.44      0.43        52\n",
      "Formal/Polite       0.72      0.77      0.74       182\n",
      "     Informal       0.59      0.55      0.57       123\n",
      "        Taboo       0.00      0.00      0.00        15\n",
      "\n",
      "     accuracy                           0.62       372\n",
      "    macro avg       0.43      0.44      0.43       372\n",
      " weighted avg       0.60      0.62      0.61       372\n",
      "\n",
      "\n",
      "\n",
      "Classifier: AdaBoost\n",
      "----------------------------------------\n",
      "Training Set Results:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Derogatory       0.67      0.04      0.08       227\n",
      "Formal/Polite       0.55      0.69      0.61       687\n",
      "     Informal       0.42      0.51      0.46       498\n",
      "        Taboo       1.00      0.07      0.12        76\n",
      "\n",
      "     accuracy                           0.50      1488\n",
      "    macro avg       0.66      0.33      0.32      1488\n",
      " weighted avg       0.55      0.50      0.46      1488\n",
      "\n",
      "Test Set Results:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Derogatory       0.20      0.02      0.04        52\n",
      "Formal/Polite       0.56      0.70      0.62       182\n",
      "     Informal       0.37      0.41      0.39       123\n",
      "        Taboo       0.00      0.00      0.00        15\n",
      "\n",
      "     accuracy                           0.48       372\n",
      "    macro avg       0.28      0.28      0.26       372\n",
      " weighted avg       0.42      0.48      0.44       372\n",
      "\n",
      "\n",
      "\n",
      "Classifier: Naive Bayes\n",
      "----------------------------------------\n",
      "Training Set Results:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Derogatory       0.86      0.92      0.89       227\n",
      "Formal/Polite       0.96      0.88      0.92       687\n",
      "     Informal       0.85      0.94      0.89       498\n",
      "        Taboo       0.87      0.79      0.83        76\n",
      "\n",
      "     accuracy                           0.90      1488\n",
      "    macro avg       0.89      0.88      0.88      1488\n",
      " weighted avg       0.90      0.90      0.90      1488\n",
      "\n",
      "Test Set Results:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Derogatory       0.55      0.40      0.47        52\n",
      "Formal/Polite       0.73      0.77      0.75       182\n",
      "     Informal       0.55      0.62      0.58       123\n",
      "        Taboo       0.25      0.07      0.11        15\n",
      "\n",
      "     accuracy                           0.64       372\n",
      "    macro avg       0.52      0.46      0.48       372\n",
      " weighted avg       0.63      0.64      0.63       372\n",
      "\n",
      "\n",
      "\n",
      "Classifier: QDA\n",
      "----------------------------------------\n",
      "Training Set Results:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Derogatory       0.98      0.90      0.94       227\n",
      "Formal/Polite       0.93      0.99      0.96       687\n",
      "     Informal       0.95      0.93      0.94       498\n",
      "        Taboo       1.00      0.84      0.91        76\n",
      "\n",
      "     accuracy                           0.95      1488\n",
      "    macro avg       0.96      0.91      0.94      1488\n",
      " weighted avg       0.95      0.95      0.95      1488\n",
      "\n",
      "Test Set Results:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Derogatory       0.25      0.52      0.34        52\n",
      "Formal/Polite       0.77      0.41      0.54       182\n",
      "     Informal       0.58      0.28      0.38       123\n",
      "        Taboo       0.07      0.47      0.12        15\n",
      "\n",
      "     accuracy                           0.39       372\n",
      "    macro avg       0.42      0.42      0.34       372\n",
      " weighted avg       0.61      0.39      0.44       372\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from bornrule import BornClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "# Add a seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"Variables are collinear\")\n",
    "\n",
    "def main():\n",
    "\n",
    "    df = pd.read_csv(r\"\")\n",
    "    \n",
    "    # Keep only rows where both classification columns are in [\"Formal/Polite\", \"Informal\", \"Derogatory\", \"Taboo\"]\n",
    "    allowed_classes = [\"Formal/Polite\", \"Informal\", \"Derogatory\", \"Taboo\"]\n",
    "    df = df[\n",
    "        df['original_sentence_classification_experts_classification'].isin(allowed_classes) &\n",
    "        df['paraphrased_sentence_classification_experts_classification'].isin(allowed_classes)\n",
    "    ]\n",
    "    \n",
    "    #  Create a list of (original_sentence, original_label, paraphrased_sentence, paraphrased_label)\n",
    "    pairs = []\n",
    "    for _, row in df.iterrows():\n",
    "        pairs.append((\n",
    "            row['original_sentence'],\n",
    "            row['original_sentence_classification_experts_classification'],\n",
    "            row['paraphrased_sentence'],\n",
    "            row['paraphrased_sentence_classification_experts_classification']\n",
    "        ))\n",
    "    \n",
    "    # Shuffle the pairs so that training/test splits are random\n",
    "    random.shuffle(pairs)\n",
    "    \n",
    "    # Train/test split on pairs (ensuring that each original and its paraphrase remain together)\n",
    "    total_pairs = len(pairs)\n",
    "    train_count = int(0.8 * total_pairs)\n",
    "    train_pairs = pairs[:train_count]\n",
    "    test_pairs  = pairs[train_count:]\n",
    "    \n",
    "    # Flatten the pairs into separate lists for X (sentences) and y (labels)\n",
    "    def flatten_pairs(pair_list):\n",
    "        X, y = [], []\n",
    "        for orig_sent, orig_label, para_sent, para_label in pair_list:\n",
    "            X.append(orig_sent)\n",
    "            y.append(orig_label)\n",
    "            X.append(para_sent)\n",
    "            y.append(para_label)\n",
    "        return X, y\n",
    "    \n",
    "    X_train, y_train = flatten_pairs(train_pairs)\n",
    "    X_test, y_test   = flatten_pairs(test_pairs)\n",
    "    \n",
    "    # Preprocess text using CountVectorizer (or maybe change vectoriser?)\n",
    "    vectorizer = CountVectorizer()\n",
    "    X_train_vect = vectorizer.fit_transform(X_train)\n",
    "    X_test_vect  = vectorizer.transform(X_test)\n",
    "    \n",
    "    X_train_dense = X_train_vect.toarray()\n",
    "    X_test_dense = X_test_vect.toarray()\n",
    "    \n",
    "    # Dictionary to store results for each classifier:\n",
    "    # Key: classifier name; Value: dictionary with 'train_report', 'test_report', 'avg_f1'\n",
    "    results = {}\n",
    "    \n",
    "    # Tracking best classifier based on average test F1 (average of macro and weighted F1)\n",
    "    best_avg_f1 = -1\n",
    "    best_classifier_name = \"\"\n",
    "    \n",
    "    def compute_avg_f1(report):\n",
    "        macro_f1 = report[\"macro avg\"][\"f1-score\"]\n",
    "        weighted_f1 = report[\"weighted avg\"][\"f1-score\"]\n",
    "        return (macro_f1 + weighted_f1) / 2.0\n",
    "    \n",
    "    # Define the classifiers.\n",
    "    # Each tuple is (name, classifier instance, requires_dense)\n",
    "    # \"requires_dense\" is True if the classifier cannot work with sparse matrix data.\n",
    "    classifiers = []\n",
    "    # Include BornClassifier (original Born's Rule)\n",
    "    classifiers.append((\"BornClassifier\", BornClassifier(a=0.5, b=1.0, h=1.0), False))\n",
    "    # Other classifiers:\n",
    "    classifiers.append((\"Nearest Neighbors\", KNeighborsClassifier(), False))\n",
    "    classifiers.append((\"Linear SVM\", LinearSVC(dual=False, max_iter=5000), False))\n",
    "    classifiers.append((\"Random Forest\", RandomForestClassifier(), True))\n",
    "    classifiers.append((\"Neural Net\", MLPClassifier(max_iter=1000), True))\n",
    "    classifiers.append((\"Naive Bayes\", MultinomialNB(), False))\n",
    "    \n",
    "    # 8. Define parameter grids for hyperparameter tuning\n",
    "    param_grids = {\n",
    "        \"BornClassifier\": {\"a\": [0.1,0.3,0.5,0.7,0.9], \"b\": [0.3,0.5, 1.5, 2.0,1], \"h\": [0.3,0.5, 1.5, 2.0,1]},\n",
    "        \"Nearest Neighbors\": {\"n_neighbors\": [2,3, 5, 7, 9,10,15,20]},\n",
    "        \"Linear SVM\": {\"C\": [0.01,0.05,0.1, 1, 10,50]},\n",
    "        \"Random Forest\": {\"n_estimators\": [50, 100, 200,300], \"max_depth\": [None, 10, 20,50], \"min_samples_split\": [2, 5,10]},\n",
    "        \"Neural Net\": {\"hidden_layer_sizes\": [(50,), (100,), (500,)], \"activation\": [\"relu\", \"tanh\"], \"alpha\": [0.0001, 0.001,0.01]},\n",
    "        \"Naive Bayes\": {\"alpha\": [0.1,0.5, 1.0, 1.5]},\n",
    "    }\n",
    "    \n",
    "    #  Train and evaluate each classifier\n",
    "    for name, clf, requires_dense in classifiers:\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"Classifier: {name}\")\n",
    "        \n",
    "        # Choose the appropriate input (dense or sparse)\n",
    "        if requires_dense:\n",
    "            X_train_used = X_train_dense\n",
    "            X_test_used = X_test_dense\n",
    "        else:\n",
    "            X_train_used = X_train_vect\n",
    "            X_test_used = X_test_vect\n",
    "        \n",
    "        # Perform grid search if a parameter grid is defined for this classifier\n",
    "        if name in param_grids and param_grids[name]:\n",
    "            print(f\"Performing grid search for {name}...\")\n",
    "            grid_search = GridSearchCV(clf, param_grids[name], cv=3, n_jobs=-1, scoring='f1_macro')\n",
    "            grid_search.fit(X_train_used, y_train)\n",
    "            print(f\"Best parameters for {name}: {grid_search.best_params_}\")\n",
    "            clf = grid_search.best_estimator_\n",
    "        \n",
    "        # Train classifier (if not already fitted by grid search)\n",
    "        clf.fit(X_train_used, y_train)\n",
    "        \n",
    "        # Evaluate on the training set\n",
    "        y_train_pred = clf.predict(X_train_used)\n",
    "        train_report_str = classification_report(y_train, y_train_pred, zero_division=0)\n",
    "        # Evaluate on the test set\n",
    "        y_test_pred = clf.predict(X_test_used)\n",
    "        test_report_str = classification_report(y_test, y_test_pred, zero_division=0)\n",
    "        test_report = classification_report(y_test, y_test_pred, output_dict=True, zero_division=0)\n",
    "        \n",
    "        # Compute average F1 (average of macro avg and weighted avg)\n",
    "        avg_f1 = compute_avg_f1(test_report)\n",
    "        \n",
    "        # Save results\n",
    "        results[name] = {\n",
    "            'train_report': train_report_str,\n",
    "            'test_report': test_report_str,\n",
    "            'avg_f1': avg_f1\n",
    "        }\n",
    "        \n",
    "        # Update best classifier if this one is higher on averae F1\n",
    "        if avg_f1 > best_avg_f1:\n",
    "            best_avg_f1 = avg_f1\n",
    "            best_classifier_name = name\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"\\nResults Summary:\\n\")\n",
    "    # Print results for each classifier; bold the name of the best classifier.\n",
    "    for name, res in results.items():\n",
    "        display_name = f\"**{name}**\" if name == best_classifier_name else name\n",
    "        print(f\"Classifier: {display_name}\")\n",
    "        print(\"-\" * 40)\n",
    "        print(\"Training Set Results:\")\n",
    "        print(res['train_report'])\n",
    "        print(\"Test Set Results:\")\n",
    "        print(res['test_report'])\n",
    "        print(\"\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
