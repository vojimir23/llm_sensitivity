# LLM Sensitivity Pipeline Documentation

## 1. Overview
The llm_sensitivity project is a research tool designed to analyze how Large Language Models (LLMs) process and handle sensitive, taboo, or informal language. The pipeline follows a structured four-stage process to ensure data integrity and reproducible results.

### The Workflow:
- **Ingestion**: Fetching real-world sentences from Sketch Engine corpora.
- **Storage**: Managing and deduplicating data in a PostgreSQL database.
- **Paraphrasing**: Generating variations of sentences via OpenAI Batch API.
- **Classification**: Evaluating the sensitivity class (e.g., Taboo, Informal) using local models (Ministral-8B).

## 2. Prerequisites
Before running the pipeline, ensure your environment meets these requirements:
- **Python**: version 3.10+
- **PostgreSQL**: A running instance with a database named llm_sensitivity.
- **API Keys**:
  - Sketch Engine: Username and API Key.
  - OpenAI: API Key (for paraphrasing tasks).
- **Local LLM**: Access to Hugging Face to download Ministral-8B GGUF files.

## 3. Installation & Configuration

## Step 1: Install Dependencies
Run the following command to install the required Python packages:

pip install requests tqdm tenacity psycopg2-binary pandas openai llama-cpp-python

## Step 2: Configuration
Update config.py with your specific credentials:

Sketch Engine: Enter USERNAME, API_KEY, and preferred CORPUS_NAME.

OpenAI: Enter OPENAI_API_KEY.

Database: Update DB_CONFIG with your PostgreSQL password and host details.

## 4. Execution Guide
## Phase 1: Sentence Fetching
This stage populates your database with original sentences containing specific target expressions.

Method A: Using an Excel File (if you have a pre-defined list of terms):

python -m src.make_sentences_and_save num_sentences min_words max_words path_to_excel


# Example:
python -m src.make_sentences_and_save 10 5 25 terms.xlsx

Method B: Direct Fetching (targets expressions already in the DB marked as 'Taboo'):

python -m src.sentence_fetcher num_sentences min_words max_words

## Phase 2: Paraphrasing
Once original sentences are stored, use the OpenAI Batch API to generate variations. This method is used to optimize costs and handle high volumes.

python -m src.paraphrase num_paraphrases_per_sentence

Note: This process uses a .jsonl upload. It may take anywhere from minutes to hours depending on OpenAI's batch queue.

## Phase 3: Classification
Evaluate the sensitivity of both original and paraphrased sentences using a local classifier (Ministral-8B via llama-cpp-python).

python -m src.llm_classifiers
The script pulls from the experts_classification join view.
Results are stored in llm_classification, including a model_system_fingerprint for scientific reproducibility.

## 5. Module Details
Module	Responsibility
data_store.py	Central DB interface. Handles Deduplication (via token_number) and relational mapping between expressions and paraphrases.
sentence_fetcher.py	Connects to Sketch Engine. Applies filters for Genre (excluding news/legal) and Sentence Length.
paraphrase.py	Leverages OpenAIâ€™s Batch API (approx. 50% cheaper). Uses templates from paraphrase_prompt.txt.
llm_classifiers.py	Local inference engine. Loads GGUF models and applies system prompts from sensitivity_prompt.txt.

## 6. Database Schema Summary
The system manages data across four primary tables:

expressions: Stores target keywords and their baseline sensitivity class.

original_sentences: The raw "source of truth" data from Sketch Engine.

paraphrased_sentences: AI-generated variations of the original sentences.

llm_classification: Final labels and metadata generated by the local LLM.

At the end, we added experts_classification results.
